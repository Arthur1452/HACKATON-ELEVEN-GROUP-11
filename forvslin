import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# =======================
# 1️⃣ Charger et préparer les données
# =======================
data = pd.read_csv("C:/Users/ouzen/Documents/HACKATON-ELEVEN-GROUP-11/waiting_times_train.csv", sep=",")

data['DATETIME'] = pd.to_datetime(data['DATETIME'])
data['hour'] = data['DATETIME'].dt.hour
data['dayofweek'] = data['DATETIME'].dt.dayofweek
data['month'] = data['DATETIME'].dt.month

# Supprimer TIME_TO_PARADE_2
data = data.drop(columns=['TIME_TO_PARADE_2']).copy()
data = pd.get_dummies(data, columns=['ENTITY_DESCRIPTION_SHORT'])

X = data.drop(columns=['DATETIME', 'WAIT_TIME_IN_2H']).copy()
y = data['WAIT_TIME_IN_2H']

# Remplir les NaN par 0 dans les colonnes parade/show
for col in ['TIME_TO_PARADE_1', 'TIME_TO_NIGHT_SHOW']:
    if col in X.columns:
        X[col] = X[col].fillna(0)

# =======================
# 2️⃣ Split train / validation
# =======================
X_train_full, X_val, y_train_full, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# =======================
# 3️⃣ GridSearch uniquement sur le train
# =======================
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5]
}

grid_search = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)

grid_search.fit(X_train_full, y_train_full)
print("Meilleurs paramètres (train seulement):", grid_search.best_params_)

# =======================
# 4️⃣ Modèle final avec les meilleurs paramètres
# =======================
rf_final = RandomForestRegressor(**grid_search.best_params_, random_state=42)
rf_final.fit(X_train_full, y_train_full)

y_val_pred = rf_final.predict(X_val)
rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))
print("RMSE sur validation jamais vue:", rmse_val)

# =======================
# 5️⃣ Comparer avec LinearRegression sur le même split
# =======================
lr_model = LinearRegression()
lr_model.fit(X_train_full, y_train_full)
y_val_pred_lr = lr_model.predict(X_val)
rmse_val_lr = np.sqrt(mean_squared_error(y_val, y_val_pred_lr))
print("RMSE LinearRegression sur validation:", rmse_val_lr)

# =======================
# 6️⃣ Visualisation
# =======================
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
sns.scatterplot(x=y_val, y=y_val_pred, alpha=0.3)
plt.xlabel("Temps d'attente réel")
plt.ylabel("Temps d'attente prédit")
plt.title("RandomForest : prédictions vs réel (validation)")

plt.subplot(1,2,2)
sns.scatterplot(x=y_val, y=y_val_pred_lr, alpha=0.3, color='orange')
plt.xlabel("Temps d'attente réel")
plt.ylabel("Temps d'attente prédit")
plt.title("LinearRegression : prédictions vs réel (validation)")

plt.tight_layout()
plt.show()
